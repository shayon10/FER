{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import timm  # For pre-trained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 23650, Validation size: 2631, Test size: 6573\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "dataset_path = r'D:\\university\\FER\\fer_ckplus_kdef'\n",
    "train_dir = os.path.join(dataset_path, 'train')\n",
    "val_dir = os.path.join(dataset_path, 'val')\n",
    "test_dir = os.path.join(dataset_path, 'test')\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Dataloader setup\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNTransFERNet(\n",
      "  (cnn): EfficientNet(\n",
      "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNormAct2d(\n",
      "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNormAct2d(\n",
      "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (classifier): Identity()\n",
      "  )\n",
      "  (transformer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=1280, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=1280, bias=True)\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1280, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNTransFERNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNTransFERNet, self).__init__()\n",
    "\n",
    "        # Pretrained CNN Backbone (EfficientNet)\n",
    "        self.cnn = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.cnn.classifier = nn.Identity()  # Remove final classification layer\n",
    "\n",
    "        # Transformer encoder layer with correct input size\n",
    "        self.transformer = nn.TransformerEncoderLayer(d_model=1280, nhead=8)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(1280, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)  # Shape: (batch_size, 1280)\n",
    "\n",
    "        # Add sequence dimension for transformer input (batch_size, seq_len=1, 1280)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Remove sequence dimension after transformer processing\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # Classification layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CNNTransFERNet(num_classes=num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after no improvement.\n",
    "            min_delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                print(f\"Early stopping triggered after {self.patience} epochs without improvement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, patience=5):\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "\n",
    "    train_loss_history, val_loss_history, train_acc_history, val_acc_history = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Evaluate the model on validation set\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        val_loss_history.append(val_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Training stopped early due to no improvement.\")\n",
    "            break\n",
    "\n",
    "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss / len(loader.dataset)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 1.8520 | Train Acc: 0.2677 | Val Loss: 1.9196 | Val Acc: 0.2752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 1.8459 | Train Acc: 0.2712 | Val Loss: 1.8921 | Val Acc: 0.2125\n",
      "Epoch 3/20 | Train Loss: 1.8422 | Train Acc: 0.2738 | Val Loss: 1.8509 | Val Acc: 0.2752\n",
      "Epoch 4/20 | Train Loss: 1.8427 | Train Acc: 0.2708 | Val Loss: 1.9675 | Val Acc: 0.1460\n",
      "Epoch 5/20 | Train Loss: 1.8384 | Train Acc: 0.2757 | Val Loss: 1.9197 | Val Acc: 0.1870\n",
      "Epoch 6/20 | Train Loss: 1.8371 | Train Acc: 0.2765 | Val Loss: 1.8993 | Val Acc: 0.2759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_loss, val_loss, train_acc, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience)\u001b[0m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 19\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_loss, val_loss, train_acc, val_acc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(train_loss, val_loss, train_acc, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    class_labels = train_dataset.classes\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_labels))\n",
    "\n",
    "test_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
