{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 23650, Validation size: 2631, Test size: 6573\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "dataset_path = r'D:\\university\\FER\\fer_ckplus_kdef'\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir = os.path.join(dataset_path, \"val\")\n",
    "test_dir = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "# Data Augmentation for Train Set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomResizedCrop(112, scale=(0.7, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Validation and Test Transformations\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=val_test_transform)\n",
    "\n",
    "# Dataloader setup\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNTransFERNet(\n",
      "  (cnn): EfficientNet(\n",
      "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNormAct2d(\n",
      "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNormAct2d(\n",
      "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (classifier): Identity()\n",
      "  )\n",
      "  (fc1): Linear(in_features=1280, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (transformer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNTransFERNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNTransFERNet, self).__init__()\n",
    "\n",
    "        # Pretrained EfficientNet backbone\n",
    "        self.cnn = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.cnn.classifier = nn.Identity()  # Remove the final classification layer\n",
    "\n",
    "        # Fully connected layers with dropout and batch normalization\n",
    "        self.fc1 = nn.Linear(1280, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        self.transformer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "\n",
    "        # Final classifier\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.transformer(x.unsqueeze(0))\n",
    "        x = self.fc2(x.squeeze(0))\n",
    "        return x\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CNNTransFERNet(num_classes=num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Reduce LR when validation loss plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "    early_stopping = EarlyStopping(patience=7)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Apply Mixup\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        val_epoch_loss, val_epoch_acc = evaluate_model(model, val_loader, criterion)\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        train_loss.append(epoch_loss)\n",
    "        val_loss.append(val_epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "        val_acc.append(val_epoch_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} -> Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "        if early_stopping(val_epoch_loss):\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    return train_loss, val_loss, train_acc, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 -> Train Loss: 1.5581, Train Acc: 0.3586, Val Loss: 1.3418, Val Acc: 0.5146\n",
      "Epoch 2/100 -> Train Loss: 1.5448, Train Acc: 0.3725, Val Loss: 1.2521, Val Acc: 0.5561\n",
      "Epoch 3/100 -> Train Loss: 1.5263, Train Acc: 0.3707, Val Loss: 1.1949, Val Acc: 0.5830\n",
      "Epoch 4/100 -> Train Loss: 1.5025, Train Acc: 0.3719, Val Loss: 1.2150, Val Acc: 0.5777\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_loss, val_loss, train_acc, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     24\u001b[0m running_loss, correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     27\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Apply Mixup\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:263\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 263\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shayon\\anaconda3\\envs\\SHgpu\\lib\\site-packages\\PIL\\Image.py:3413\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pixels \u001b[38;5;241m>\u001b[39m MAX_IMAGE_PIXELS:\n\u001b[0;32m   3406\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3407\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels) exceeds limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_IMAGE_PIXELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3408\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould be decompression bomb DOS attack.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3409\u001b[0m             DecompressionBombWarning,\n\u001b[0;32m   3410\u001b[0m         )\n\u001b[1;32m-> 3413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\n\u001b[0;32m   3414\u001b[0m     fp: StrOrBytesPath \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   3415\u001b[0m     mode: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3416\u001b[0m     formats: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3417\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImageFile\u001b[38;5;241m.\u001b[39mImageFile:\n\u001b[0;32m   3418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;124;03m    Opens and identifies the given image file.\u001b[39;00m\n\u001b[0;32m   3420\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3444\u001b[0m \u001b[38;5;124;03m    :exception TypeError: If ``formats`` is not ``None``, a list or a tuple.\u001b[39;00m\n\u001b[0;32m   3445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_loss, val_loss, train_acc, val_acc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Val Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy')\n",
    "    plt.plot(val_acc, label='Val Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(train_loss, val_loss, train_acc, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    class_labels = train_dataset.classes\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_labels))\n",
    "\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_transFERNet1.pth')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_save_path = \"cnn_transFERNet1.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# List of files to include in the ZIP\n",
    "files_to_zip = [\"cnn_transFERNet.pth\", \"cnn_transFERNet_training.py\"]\n",
    "\n",
    "# Create ZIP archive\n",
    "zip_file_name = \"cnn_transFERNet_project.zip\"\n",
    "with shutil.ZipFile(zip_file_name, 'w') as zipf:\n",
    "    for file in files_to_zip:\n",
    "        zipf.write(file)\n",
    "\n",
    "print(f\"Created {zip_file_name} successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
